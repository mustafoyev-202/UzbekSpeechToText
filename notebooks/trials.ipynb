{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-04T14:38:26.055799Z",
     "start_time": "2024-10-04T14:38:26.045804Z"
    }
   },
   "source": [
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pyaudio\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T14:38:26.761659Z",
     "start_time": "2024-10-04T14:38:26.740665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))"
   ],
   "id": "eb932089cca7440c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T14:38:27.136943Z",
     "start_time": "2024-10-04T14:38:27.116946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the Hugging Face model and processor for Uzbek speech-to-text\n",
    "def load_uzbek_stt_model():\n",
    "    processor = Wav2Vec2Processor.from_pretrained(\"oyqiz/uzbek_stt\")\n",
    "    model = Wav2Vec2ForCTC.from_pretrained(\"oyqiz/uzbek_stt\")\n",
    "    return processor, model"
   ],
   "id": "f51dcdbd9481629a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T14:38:27.463689Z",
     "start_time": "2024-10-04T14:38:27.454686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to perform speech-to-text using 'oyqiz/uzbek_stt'\n",
    "def uzbek_speech_to_text(audio_data):\n",
    "    processor, model = load_uzbek_stt_model()\n",
    "\n",
    "    # Resample if needed and convert audio to the appropriate format\n",
    "    audio_data = librosa.resample(audio_data, orig_sr=sr, target_sr=16000)\n",
    "    input_values = processor(audio_data, return_tensors=\"pt\", padding=\"longest\").input_values\n",
    "\n",
    "    # Perform inference (Uzbek speech-to-text)\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    # Convert the predicted IDs to transcribed text\n",
    "    transcription = processor.batch_decode(predicted_ids)[0]\n",
    "    return transcription"
   ],
   "id": "40b5225f4f1e9046",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T14:38:27.931602Z",
     "start_time": "2024-10-04T14:38:27.915599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use Gemini to summarize text\n",
    "def generate_gemini_content(text, prompt):\n",
    "    model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
    "    full_prompt = (\n",
    "        f\"{prompt}\\n\"\n",
    "        \"Matnni qisqartirib, asosiy fikrlarni bullet point ko'rinishida taqdim qiling. \"\n",
    "        \"Matnni ijobiy yoki salbiy ekanligini ham aniqlang.\"\n",
    "    )\n",
    "    response = model.generate_content(full_prompt + text)\n",
    "    return response.text"
   ],
   "id": "f962a50f3b63fa63",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T14:38:28.293330Z",
     "start_time": "2024-10-04T14:38:28.287329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load audio from file and perform speech-to-text\n",
    "def process_uploaded_audio(file_path):\n",
    "    # Load the audio file and perform conversion\n",
    "    audio_data, sr = librosa.load(file_path, sr=16000)\n",
    "    transcription = uzbek_speech_to_text(audio_data)\n",
    "\n",
    "    print(\"Transcribed Text: \", transcription)\n",
    "    prompt = \"Quyidagi matnni tahlil qilib, qisqacha mazmunini chiqarib bering:\"\n",
    "    summary = generate_gemini_content(transcription, prompt)\n",
    "    print(\"Summary: \", summary)"
   ],
   "id": "4dabe8b71b7b9bf4",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T14:38:28.778731Z",
     "start_time": "2024-10-04T14:38:28.756733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to capture microphone input\n",
    "def capture_microphone_input(duration=5, sr=16000):\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    # Setup recording parameters\n",
    "    stream = p.open(format=pyaudio.paInt16,\n",
    "                    channels=1,\n",
    "                    rate=sr,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=1024)\n",
    "\n",
    "    print(\"Recording...\")\n",
    "    frames = []\n",
    "\n",
    "    for _ in range(0, int(sr / 1024 * duration)):\n",
    "        data = stream.read(1024)\n",
    "        frames.append(np.frombuffer(data, dtype=np.int16))\n",
    "\n",
    "    print(\"Finished recording.\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    # Convert the list of arrays to a single numpy array\n",
    "    audio_data = np.concatenate(frames).astype(np.float32) / np.iinfo(np.int16).max\n",
    "\n",
    "    return audio_data, sr"
   ],
   "id": "f00c9189bd3a87b2",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Main part of the code for interactive input\n",
    "option = input(\"Choose input method (1 for file upload, 2 for microphone): \")\n",
    "\n",
    "if option == \"1\":\n",
    "    file_path = \"../Operator-va-menejerlar-uchun-o-quv-kursi-kirish-va-chiqish.mp3\"\n",
    "    process_uploaded_audio(file_path)\n",
    "\n",
    "elif option == \"2\":\n",
    "    duration = int(input(\"Enter the recording duration in seconds: \"))\n",
    "    audio_data, sr = capture_microphone_input(duration)\n",
    "    uzbek_text = uzbek_speech_to_text(audio_data)\n",
    "    print(\"Transcribed Text:\", uzbek_text)\n",
    "\n",
    "    # Perform summarization with Gemini\n",
    "    prompt = \"Quyidagi matnni tahlil qilib, qisqacha mazmunini chiqarib bering:\"\n",
    "    summary = generate_gemini_content(uzbek_text, prompt)\n",
    "    print(\"Summary:\", summary)"
   ],
   "id": "5bbab4f0ea1f2311"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
